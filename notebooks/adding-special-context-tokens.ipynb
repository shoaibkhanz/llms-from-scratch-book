{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b21639-ef86-4302-9c5f-f33e479c5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2b345a-a635-4830-b56c-4ec6392ab2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the text 20559\n",
      "\n",
      " The Verdict: Edith Wharton: 1908\n",
      "Exported from Wikisource on October 21, 2024\n",
      "\n",
      "I HAD always thought\n"
     ]
    }
   ],
   "source": [
    "with open(Path(\"../resources/verdict.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    verdict = f.read()\n",
    "\n",
    "print(f\"length of the text {len(verdict)}\")\n",
    "print(\"\\n\", verdict[:99])\n",
    "\n",
    "# We have now confirmed the length of the text, and the also printed the first 99 characters and \n",
    "# the length includes the spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201450e4-798d-4b31-91b5-094e56fdffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex_logic = r\"([,.:;?_!\\\"()']|--|\\s)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcffa57f-c3b2-46ee-b4cf-b1fd03a4c2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4705\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = re.split(regex_logic, verdict)\n",
    "preprocessed_text = [text.strip() for text in preprocessed_text if text.strip()]\n",
    "print(len(preprocessed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b66a06-340a-4cf4-9121-f1f3f2403363",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = sorted(set(preprocessed_text))\n",
    "all_words.extend([\"<|unk|>\",\"<|endoftext|>\"])\n",
    "\n",
    "\n",
    "#word_mapping = {}\n",
    "#for i,word in enumerate(all_words):\n",
    "#    word_mapping[word]= i\n",
    "\n",
    "# much more concise way of writing the above, with a slight change in the output using () \n",
    "# would be the following\n",
    "vocab = {word: idx for idx, word in enumerate(all_words)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af5d293e-8975-4538-b9c0-698de5b5deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab) # we now have the extended dictionary with 2 special tokens added.\n",
    "# 'would': 1129, 'wouldn': 1130, 'year': 1131, 'years': 1132, 'yellow': 1133, 'yet': 1134, \n",
    "# 'you': 1135, 'younger': 1136, 'your': 1137, 'yourself': 1138, '<|unk|>': 1139, '<|endoftext|>': 1140}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ed348d-eafc-4fe9-b5ea-4da3a2970b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1136)\n",
      "('your', 1137)\n",
      "('yourself', 1138)\n",
      "('<|unk|>', 1139)\n",
      "('<|endoftext|>', 1140)\n"
     ]
    }
   ],
   "source": [
    "for items in list(vocab.items())[-5:]:\n",
    "    print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b8060a3-d8be-457d-93ff-025fbc2c7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {idx:token for token, idx in vocab.items()}\n",
    "\n",
    "    def encode(self,text):\n",
    "        preprocess_text = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        # note that the if text.strip() validates whether the stripped text is not empty\n",
    "        # filtering out empty or whitespace only strings. The next strip strips the space from the text.\n",
    "        # and adds that to the preprocess list.\n",
    "        preprocess_text = [text.strip() for text in preprocess_text if text.strip()]\n",
    "        preprocess_text =[text if text in self.str_to_int else \"<|unk|>\" for text in preprocess_text]\n",
    "        ids = [self.str_to_int[text] for text in preprocess_text]\n",
    "        return ids\n",
    "\n",
    "    def decode(self,ids):\n",
    "        text= \" \".join([self.int_to_str[i] for i in ids])\n",
    "        final_text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be9a2a5-be39-4adf-83ad-2c00a188b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokeniser = SimpleTokenizerV2(vocab)\n",
    "text1= \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1,text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b47611-209a-4f83-a0f1-b051dfd81c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1139, 5, 364, 1135, 637, 984, 13, 1140, 60, 997, 965, 993, 731, 997, 1139, 7]\n"
     ]
    }
   ],
   "source": [
    "print(tokeniser.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cadafb1-e127-4996-88bb-c8aebaaaf363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokeniser.decode(tokeniser.encode(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d35e05-88dc-4d38-aa93-c6650551a17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
