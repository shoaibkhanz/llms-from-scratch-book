{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd1fd22f-f992-4589-90ce-fc1223bb5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "991fae16-86ed-45c3-b86f-9114818dd6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
      "3\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "print(probas)\n",
    "print(torch.argmax(probas).item())\n",
    "print(inverse_vocab[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc8caeed-12d4-47c1-8d8a-ef55b4e24e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51755b13-fb1f-477d-be6f-0f127e55bf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf1ec206-4105-439e-9ff2-bda02c1e4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_ids = torch.bincount(torch.tensor(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4788461a-c29a-4b88-a5e0-fe4a462efe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 73,   0,   0, 582,   2,   0,   0, 343])\n"
     ]
    }
   ],
   "source": [
    "print(sampled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f605d05-d96f-4969-801d-a8662dbbfab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "for i , freq in enumerate(sampled_ids):\n",
    "    print(f\"{freq} x {inverse_vocab[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af220ee2-37e1-4ee7-85d7-5f825ef77d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    probas = torch.softmax(logits/temperature,dim=0)\n",
    "    return probas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19b93596-7e0c-425f-9c7d-07945e8d1552",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures =[1,0.1,5]\n",
    "scaled_probas= [softmax_with_temperature(next_token_logits, t) for t in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b576458-980b-4f5d-9c35-6038802bf676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
       "         1.0120e-04, 3.5758e-01, 4.0122e-03]),\n",
       " tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
       "         2.9718e-38, 9.0133e-03, 2.8514e-22]),\n",
       " tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a454530-3402-4011-84db-699cab174460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([6.7500, 6.2800, 4.5100]),\n",
       "indices=tensor([3, 7, 0]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(next_token_logits,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "339bb08e-1401-44fe-83fa-a2816a98b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "cur_dir= Path().cwd().parents[0]\n",
    "#print(cur_dir)\n",
    "sys.path.append(str(cur_dir))\n",
    "from src.model.transformer_block import CONFIG, GPTModel_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7542336f-0204-40f4-b9ee-29c8f295a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2_small_config = {\n",
    "    \"vocab_size\": 50257,  # Size of the vocabulary used by the model\n",
    "    \"context_length\": 1024,  # Maximum length of input sequences\n",
    "    \"emb_dim\": 256,  # Dimensionality of the model's embeddings (d_model)\n",
    "    \"n_heads\": 16,  # Number of attention heads in the multi-head attention mechanism\n",
    "    \"n_layers\": 24,  # Number of transformer layers in the model\n",
    "    \"drop_rate\": 0.1,  # Dropout rate for regularization\n",
    "    \"qkv_bias\": False,  # Whether to include bias terms in the query, key, and value projections\n",
    "}\n",
    "\n",
    "model = GPTModel_v2(GPT2_small_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "731729e0-4bd5-4bd6-9709-610e764fa255",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76fbdf28-e576-4627-bb60-a0d8951dfbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= torch.optim.AdamW(model.parameters(), lr= 0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40e5a842-c47f-47b5-9e71-ce83abe76650",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"model\":model.state_dict(), \"optimizer\":optimizer.state_dict()},\n",
    "           \"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300154fd-5fb0-4b7e-af02-6017c8b6b074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a293f16-23d8-4f04-bc46-53a23e2484cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
