{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601d347a-de6a-4299-b13e-22ed60bca356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e49a723-2218-4c12-8231-a52d8c4c6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your journey starts with one step\n",
    "torch.manual_seed(123)\n",
    "inputs = torch.rand((6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e678606e-83ec-4e85-abde-857a00c00756",
   "metadata": {},
   "outputs": [],
   "source": [
    "din=3\n",
    "dout=2\n",
    "wq = torch.nn.Parameter(torch.randn(din,dout),requires_grad=True)\n",
    "wk = torch.nn.Parameter(torch.randn(din,dout),requires_grad=True)\n",
    "wv = torch.nn.Parameter(torch.randn(din,dout),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4896083f-5023-4c65-b5c7-542afd0840fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we treat journey vector as our query vector\n",
    "x2 = inputs[1]\n",
    "query2 = x2 @ wq\n",
    "# to get context vectors we would need the keys and values across the full input\n",
    "keys = inputs @ wk\n",
    "values = inputs @ wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65236611-dac5-4e8b-b72b-ed5f3545ca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([6, 2])\n",
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "print(query2.shape)\n",
    "print(keys.shape)\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebcccfc-b14e-4ec3-9dd8-f42432fb13b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "attention_score = query2 @ keys.T\n",
    "print(attention_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a044ec78-862b-47f5-96c1-3373d9fd864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1976, 0.3041, 0.1116, 0.1607, 0.3675, 0.5791],\n",
      "       grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(attention_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5288f9a-9f96-4b84-87d7-ecfa20e4c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise attention score to get attention weights\n",
    "dk = 2 # dk is embedding dimension of the model, howeveer here I have not used the embedding \n",
    "# dimension, we will used this specific parameter later \n",
    "attention_weights = torch.softmax(attention_score/(dk**0.5), dim= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f700f57-3b21-4798-99f8-a78a52fd6603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1555, 0.1677, 0.1463, 0.1515, 0.1754, 0.2036],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(attention_weights)\n",
    "print(attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9511dff-6994-4c18-b3ad-99afa63ef97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector = attention_score @ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f34e514-473e-4884-96b1-e1bf72439cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.1386,  0.7401], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cd5793c-da1a-48f1-9974-940a4c5be2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "# if we now consider the full query vector the output sizes would also change\n",
    "query = inputs @ wq\n",
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d41dc78c-1bf2-4a86-89ca-2308b5d0e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attention_score = query @ keys.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13a0e1a1-b3cc-4dd0-beae-65fa61bc0535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "print(full_attention_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb225be-cedc-4725-a615-5f57405034a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attention_weights = torch.softmax(full_attention_score/(dk**0.5), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48bc6b6c-9ca5-46ae-bd9e-9d5aa9f2c62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "print(full_attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e16bbb6-397c-4c0e-b455-9063a644bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "full_context = full_attention_weights @ values\n",
    "print(full_context.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83e8ba41-46f0-4c85-94f7-17d34dd5da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6836,  0.3672],\n",
      "        [-1.7127,  0.3734],\n",
      "        [-1.6905,  0.3618],\n",
      "        [-1.6909,  0.3751],\n",
      "        [-1.7109,  0.3617],\n",
      "        [-1.7347,  0.3683]], grad_fn=<MmBackward0>)\n",
      "tensor([-3.1386,  0.7401], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(full_context)\n",
    "print(context_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
