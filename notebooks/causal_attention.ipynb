{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor( [[0.43, 0.15, 0.89], [0.55, 0.87, 0.66], \n",
    "                        [0.57, 0.85, 0.64], [0.22, 0.58, 0.33], \n",
    "                        [0.77, 0.25, 0.10], [0.05, 0.80, 0.55]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]],\n",
      "\n",
      "        [[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]]])\n",
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "# create a sample batch manually\n",
    "batch = torch.stack((inputs, inputs),dim=0)\n",
    "print(batch)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CausalAttention(nn.Module):\n",
    "#     def __init__(self, d_in, d_out, qkv_bias, context_length, dropout) -> None:\n",
    "#         super().__init__()\n",
    "#         self.d_in = d_in\n",
    "#         self.d_out = d_out\n",
    "#         self.qkv_bias = qkv_bias\n",
    "#         self.context_length = context_length\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.wq = nn.Linear(self.d_in,self.d_out,bias=self.qkv_bias)\n",
    "#         self.wk = nn.Linear(self.d_in,self.d_out,bias=self.qkv_bias)\n",
    "#         self.wv = nn.Linear(self.d_in,self.d_out,bias=self.qkv_bias)\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         query   = self.wq(inputs)\n",
    "#         keys = self.wk(inputs)\n",
    "#         values= self.wv(inputs)\n",
    "\n",
    "#         attention_scores = query @ keys.T\n",
    "#         d_k = keys.shape[-1]\n",
    "#         attention_weights = torch.softmax(attention_scores/d_k **0.5,dim = -1)\n",
    "#         mask = torch.triu(torch.ones(self.context_length, self.context_length),diagonal=1)\n",
    "#         masked_attention_weights = attention_weights * mask\n",
    "#         dropout_masked_weights = self.dropout(masked_attention_weights)\n",
    "#         context_vector = dropout_masked_weights @ values\n",
    "#         return context_vector\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4300, 0.1500, 0.8900],\n",
      "        [0.5500, 0.8700, 0.6600],\n",
      "        [0.5700, 0.8500, 0.6400],\n",
      "        [0.2200, 0.5800, 0.3300],\n",
      "        [0.7700, 0.2500, 0.1000],\n",
      "        [0.0500, 0.8000, 0.5500]])\n",
      "torch.Size([6, 3])\n",
      "torch.Size([3, 6])\n",
      "tensor([[0.4300, 0.5500, 0.5700, 0.2200, 0.7700, 0.0500],\n",
      "        [0.1500, 0.8700, 0.8500, 0.5800, 0.2500, 0.8000],\n",
      "        [0.8900, 0.6600, 0.6400, 0.3300, 0.1000, 0.5500]])\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(inputs.shape)\n",
    "print(inputs.T.shape)\n",
    "print(inputs.transpose(0,1))\n",
    "print(inputs.transpose(0,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,qkv_bias=False,):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.wq = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.wk = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.wv = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, num_tokens, d_in = x.shape\n",
    "        query = self.wq(x)\n",
    "        keys = self.wk(x)\n",
    "        values = self.wv(x)\n",
    "        attention_scores = query @ keys.transpose(1,2) # this simply swaps the dimensions.\n",
    "        masked_attention_scores = attention_scores.masked_fill(self.mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
    "        attention_weights = torch.softmax(masked_attention_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        context_vector = attention_weights @ values\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "d_in = 3\n",
    "d_out = 2\n",
    "causal_attention = CausalAttention(d_in,d_out,context_length,dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2])\n",
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "context_vectors = causal_attention(batch)\n",
    "print(context_vectors.shape)\n",
    "print(context_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
