{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f0215a-ad62-4c6d-9ddf-455325022e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4863462-d129-4f91-99ae-785d6617cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57675c7d-0d1c-4432-8d23-36edf36ee5f9",
   "metadata": {},
   "source": [
    "Here we take the text assuming coming from different batches of data representing different documents,\n",
    "we are able to encode the text into token ids using the byte pair encoding and the reverse the process using the decode function to return the text back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd02336-b7ce-442a-bf74-24825465b39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownplce.\n"
     ]
    }
   ],
   "source": [
    "text1= \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of someunknownplce.\"\n",
    "text = \" <|endoftext|> \".join((text1,text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9aa3ee-10cc-48aa-b4fb-1c17ead6d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokeniser.encode(text, allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ddcdbc6-0f7c-4e3a-95c0-1e178fbcfddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496,\n",
       " 11,\n",
       " 466,\n",
       " 345,\n",
       " 588,\n",
       " 8887,\n",
       " 30,\n",
       " 220,\n",
       " 50256,\n",
       " 554,\n",
       " 262,\n",
       " 4252,\n",
       " 18250,\n",
       " 8812,\n",
       " 2114,\n",
       " 286,\n",
       " 617,\n",
       " 34680,\n",
       " 489,\n",
       " 344,\n",
       " 13]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83dedac-eff7-4879-ac64-bb913631eb67",
   "metadata": {},
   "source": [
    "Notice how we were able to convert an unknown word with a spelling error into token ids and then convert it back to the correct text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9b162c3-0d25-4828-992a-810fff5e96b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownplce.\n"
     ]
    }
   ],
   "source": [
    "text_back = tokeniser.decode(token_ids)\n",
    "print(text_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ffda2b-8968-4f2c-9efd-ce7c2650c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n"
     ]
    }
   ],
   "source": [
    "random_word = \"Akwirw ier\"\n",
    "random_word_token_ids = tokeniser.encode(random_word)\n",
    "print(random_word_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f71d6f22-589a-42c1-a4d5-b512c0d30943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ak', 'w', 'ir', 'w', ' ', 'ier']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokeniser.decode([token]) for token in random_word_token_ids]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
