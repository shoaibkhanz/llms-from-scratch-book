{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513b4b22-3f98-457a-8f62-f06e0b741bef",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "We have used the text called verdict, which is a short story containing roughly around 25,000 characters. The txt file is saved in resources directory and we will read it next, to explore the text in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912a3d25-c9fe-49e3-9372-b414ba3672c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0528fd5-9bf0-40b3-923a-31973abe478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the text 20559\n",
      "\n",
      " The Verdict: Edith Wharton: 1908\n",
      "Exported from Wikisource on October 21, 2024\n",
      "\n",
      "I HAD always thought\n"
     ]
    }
   ],
   "source": [
    "with open(Path(\"../resources/verdict.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    verdict = f.read()\n",
    "\n",
    "print(f\"length of the text {len(verdict)}\")\n",
    "print(\"\\n\", verdict[:99])\n",
    "\n",
    "# We have now confirmed the length of the text, and the also printed the first 99 characters and \n",
    "# the length includes the spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc8bd5-9814-4d69-9f4e-ce4a277805c9",
   "metadata": {},
   "source": [
    "## Simple Tokenisation\n",
    "\n",
    "Here we will tokenise the text into words and special characters, we will start with a regular expression approach and then later switch to a more sophisticated approach such as Byte Pair Encodings using a python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0c2aa4-7a7c-4ad0-ac8c-18647d47ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#simple example\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r\"(\\s)\",text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c57a1-4df1-43c1-8df4-894243d2b7eb",
   "metadata": {},
   "source": [
    "Here we noted that the strings are still connected with the special characters and the idea would be to split them too, so that we have words and special characters by themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9eddc12-03be-416b-8708-81a04dfaadc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r\"([.,]|\\s)\", text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375fd119-050b-4174-a3ec-5a23e67249e9",
   "metadata": {},
   "source": [
    "An important note concerning tokenisation, here we can split the words and spaces but if our model needs to understand the nuances of generating code then getting rid of spaces or tabs can be detremental to the performance of the model so much so that it will generate code thats not atleast entirely executable and would require some work to get it in correct shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb11139b-fee4-4fac-b253-d89bf36c095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'Is', ' ', 'this', '--', '', ' ', 'a', ' ', 'test', '?', '']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "regex_logic = r\"([,.:;?_!\\\"()']|--|\\s)\"\n",
    "result = re.split(regex_logic, text) # r represents raw string literal, \n",
    "# which tells python to interpret backslashes in the string as escape characters.\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e767da-b3f2-469a-87c3-a692ec72931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n",
      "new result --> ['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "# We can further remove the spaces between the characters.\n",
    "# note that strip strips the text on space and returns a list without spaces.\n",
    "print([item for item in result if item.strip()])\n",
    "\n",
    "new_result = [item.strip() for item in result if item.strip()]\n",
    "print(f\"new result --> {new_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1204ca-c630-47c1-9cb2-a5af8724fb18",
   "metadata": {},
   "source": [
    "Now lets apply to the verdict text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe14e257-a42e-4ded-94c8-6c23bbd9d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4705\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = re.split(regex_logic, verdict)\n",
    "preprocessed_text = [text.strip() for text in preprocessed_text if text.strip()]\n",
    "print(len(preprocessed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45bc7c3-7aaf-4780-b618-5ab0291afcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Verdict', ':', 'Edith', 'Wharton', ':', '1908', 'Exported', 'from', 'Wikisource', 'on', 'October', '21', ',', '2024', 'I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_text[:30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
