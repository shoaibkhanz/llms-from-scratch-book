{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edffd1fa-7663-455d-91ae-fa1178ca6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba23bc2d-2bd6-4f4b-9fcb-a0eb185c13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.wq = nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.wk = nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.wv = nn.Parameter(torch.randn(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        query = x @ self.wq\n",
    "        keys= x @ self.wk\n",
    "        values = x @ self.wv\n",
    "\n",
    "        attention_score = query @ keys.T\n",
    "        attention_weights = torch.softmax(attention_score/(keys.shape[-1]** 0.5), dim = -1)\n",
    "        context_vectors = attention_weights @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53c95ee-ff48-4239-aeda-9729adee46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "inputs = torch.rand((6,3))\n",
    "\n",
    "d_in = 3\n",
    "d_out = 2\n",
    "sa_v1 = SelfAttentionV1(d_in,d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7dc864-eeca-49a6-bc28-6a13e8ad0de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6836,  0.3672],\n",
      "        [-1.7127,  0.3734],\n",
      "        [-1.6905,  0.3618],\n",
      "        [-1.6909,  0.3751],\n",
      "        [-1.7109,  0.3617],\n",
      "        [-1.7347,  0.3683]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(sa_v1(inputs)) # if you compare this output with the output from the other notebook\n",
    "# self_attention_with_trainable_weights.ipynb you will find that it matches exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663484a3-c66a-4534-8cfc-cbc7e0d1e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.wq = nn.Linear(d_in, d_out,bias=qkv_bias)\n",
    "        self.wk = nn.Linear(d_in, d_out,bias=qkv_bias)\n",
    "        self.wv = nn.Linear(d_in, d_out,bias=qkv_bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        query= self.wq(x)\n",
    "        keys = self.wk(x)\n",
    "        values = self.wv(x)\n",
    "\n",
    "        attention_score = query @ keys.T\n",
    "        attention_weights = torch.softmax(attention_score/(keys.shape[-1]**0.5),dim=-1)\n",
    "        context_matrix= attention_weights @ values\n",
    "        return context_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f406facf-5b56-4f20-8a72-4c50f5b79caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "inputs = torch.rand((6,3))\n",
    "\n",
    "d_in = 3\n",
    "d_out = 2\n",
    "sa_v2 = SelfAttentionV2(d_in,d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93c97e3-48d7-4d57-a474-ff23bb173ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3801, 0.1600],\n",
      "        [0.3776, 0.1624],\n",
      "        [0.3817, 0.1591],\n",
      "        [0.3783, 0.1620],\n",
      "        [0.3802, 0.1597],\n",
      "        [0.3773, 0.1621]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebe584-8d7e-4f0c-8737-83a8749a0577",
   "metadata": {},
   "source": [
    "**The following is the exercise 3.1 from the book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a666879-6d46-4f31-861d-673cf3d5a200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wq.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1362,  0.1853,  0.4083],\n",
       "          [ 0.1076,  0.1579,  0.5573]], requires_grad=True)),\n",
       " ('wk.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2604,  0.1829, -0.2569],\n",
       "          [ 0.4126,  0.4611, -0.5323]], requires_grad=True)),\n",
       " ('wv.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.4929,  0.2757,  0.2516],\n",
       "          [ 0.2377,  0.4800, -0.0762]], requires_grad=True))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets extract the the linear weights of query, keys and values.\n",
    "list(sa_v2.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d74acc1-ef14-4e6f-a7f4-9fce6a7befbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wq.weight',\n",
       " Parameter containing:\n",
       " tensor([[-0.1362,  0.1853,  0.4083],\n",
       "         [ 0.1076,  0.1579,  0.5573]], requires_grad=True))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the parameters\n",
    "list(sa_v2.named_parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "868a9e38-96b8-4a1f-ac59-db35432f1990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1362,  0.1853,  0.4083], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get parameter by name\n",
    "sa_v2.get_parameter(\"wq.weight\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36af89e-9ea8-401e-aecf-3b3528fbcefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list= []\n",
    "weights = [\"wq\", \"wk\",\"wv\"]\n",
    "for weight in weights:\n",
    "    weight_list.append(sa_v2.get_parameter(f\"{weight}.weight\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaee75b8-fee0-4604-b2c5-21a93ea90446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.1362,  0.1853,  0.4083], grad_fn=<SelectBackward0>),\n",
       " tensor([-0.2604,  0.1829, -0.2569], grad_fn=<SelectBackward0>),\n",
       " tensor([0.4929, 0.2757, 0.2516], grad_fn=<SelectBackward0>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c7418-5226-421c-9ad5-24cd8849fd92",
   "metadata": {},
   "source": [
    "**I found rather than using `get_parameter` I can simply use `state_dict` to access weights and assign them, so below I try that again, using `get_parameter` complicates things as it also copies the `grad_fn`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4e7e10f-6bde-4435-9894-98bfd57331e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight list:  [tensor([[-0.1362,  0.1853,  0.4083],\n",
      "        [ 0.1076,  0.1579,  0.5573]]), tensor([[-0.2604,  0.1829, -0.2569],\n",
      "        [ 0.4126,  0.4611, -0.5323]]), tensor([[ 0.4929,  0.2757,  0.2516],\n",
      "        [ 0.2377,  0.4800, -0.0762]])]\n"
     ]
    }
   ],
   "source": [
    "weight_list = []\n",
    "weights = [\"wq\", \"wk\",\"wv\"]\n",
    "for weight in weights:\n",
    "    #print(weight)\n",
    "    weight_list.append(sa_v2.state_dict()[f\"{weight}.weight\"])\n",
    "    \n",
    "print(\"weight list: \", weight_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea34c10a-7046-4b11-b041-bc44c939661a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wq tensor([[-0.1362,  0.1076],\n",
      "        [ 0.1853,  0.1579],\n",
      "        [ 0.4083,  0.5573]])\n",
      "wk tensor([[-0.2604,  0.4126],\n",
      "        [ 0.1829,  0.4611],\n",
      "        [-0.2569, -0.5323]])\n",
      "wv tensor([[ 0.4929,  0.2377],\n",
      "        [ 0.2757,  0.4800],\n",
      "        [ 0.2516, -0.0762]])\n"
     ]
    }
   ],
   "source": [
    "for param, weight in zip(weights, weight_list):\n",
    "    print(param, weight.T)\n",
    "    sa_v1.state_dict()[param].copy_(weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4ece957-7a4f-455d-ac05-df673264e179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wq',\n",
       "              tensor([[-0.1362,  0.1076],\n",
       "                      [ 0.1853,  0.1579],\n",
       "                      [ 0.4083,  0.5573]])),\n",
       "             ('wk',\n",
       "              tensor([[-0.2604,  0.4126],\n",
       "                      [ 0.1829,  0.4611],\n",
       "                      [-0.2569, -0.5323]])),\n",
       "             ('wv',\n",
       "              tensor([[ 0.4929,  0.2377],\n",
       "                      [ 0.2757,  0.4800],\n",
       "                      [ 0.2516, -0.0762]]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_v1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38cec281-3e6d-46d1-8c18-da030f111ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wq.weight',\n",
       "              tensor([[-0.1362,  0.1853,  0.4083],\n",
       "                      [ 0.1076,  0.1579,  0.5573]])),\n",
       "             ('wk.weight',\n",
       "              tensor([[-0.2604,  0.1829, -0.2569],\n",
       "                      [ 0.4126,  0.4611, -0.5323]])),\n",
       "             ('wv.weight',\n",
       "              tensor([[ 0.4929,  0.2757,  0.2516],\n",
       "                      [ 0.2377,  0.4800, -0.0762]]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_v2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f57f4051-b109-4395-b413-d234f13b6377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3801, 0.1600],\n",
       "        [0.3776, 0.1624],\n",
       "        [0.3817, 0.1591],\n",
       "        [0.3783, 0.1620],\n",
       "        [0.3802, 0.1597],\n",
       "        [0.3773, 0.1621]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_v1(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22e5239b-e9d6-46a3-a235-9f2bb0e556ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3801, 0.1600],\n",
       "        [0.3776, 0.1624],\n",
       "        [0.3817, 0.1591],\n",
       "        [0.3783, 0.1620],\n",
       "        [0.3802, 0.1597],\n",
       "        [0.3773, 0.1621]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_v2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457b39a-f377-45c2-8eb2-11da833fffb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
